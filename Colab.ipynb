{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1fd88f8",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "890592d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "def rotate_enhance(data_path):\n",
    "    for class_ in os.listdir(data_path):\n",
    "        dir_path = data_path + '/%s'%class_\n",
    "        image_list = os.listdir(dir_path)\n",
    "        print(\"目前處理Class：%s\"%class_)\n",
    "        for item in image_list:\n",
    "            img = Image.open(dir_path + \"/%s\"%item)\n",
    "            angle = 0\n",
    "            op = [Image.ROTATE_90,Image.ROTATE_180,Image.ROTATE_270]\n",
    "            for i in op:\n",
    "                new_img = img.transpose(i)\n",
    "                new_img.save(dir_path +\"/%s_%d.jpg\"%(item,angle))\n",
    "                new_img = new_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                new_img.save(dir_path +\"/%s_copy.jpg\"%item)\n",
    "                angle += 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "453ebbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前處理Class：0\n",
      "目前處理Class：1\n"
     ]
    }
   ],
   "source": [
    "rotate_enhance(\"./data/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdc63e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e70ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4253 images were found in the dataset.\n",
      "4253 images for training.\n",
      "0 images for validation.\n",
      "Using 2 dataloader workers every process\n",
      "載入pretrained\n",
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=['layers.0.blocks.1.attn_mask', 'layers.1.blocks.1.attn_mask', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.17.attn_mask'])\n",
      "[train epoch 0] loss: 0.662, acc: 0.614:   1%|▍                                      | 22/2127 [00:11<11:25,  3.07it/s]"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr 29 12:24:13 2022\n",
    "\n",
    "@author: Kyle\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils import read_split_data, train_one_epoch,evaluate\n",
    "from my_dataset import MyDataSet\n",
    "from model import swin_large_patch4_window12_384_in22k\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    num_classes = 2\n",
    "    epochs = 100\n",
    "    batch_size = 2\n",
    "    lr = 2e-6\n",
    "    img_size = 384\n",
    "    \n",
    "    data_path = \"./data/train\"\n",
    "    weights = './pretrained/swin_large_patch4_window12_384_22k.pth'\n",
    "    device = 'cuda:0'\n",
    "    \n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if os.path.exists(\"./weights\") is False:\n",
    "        os.makedirs(\"./weights\")\n",
    "    \n",
    "    \n",
    "    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(data_path)\n",
    "    \n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.Resize([img_size,img_size]),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        \"val\": transforms.Compose([transforms.Resize([img_size,img_size]),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "    \n",
    "    train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                              images_class=train_images_label,\n",
    "                              transform=data_transform[\"train\"])\n",
    "    \n",
    "    val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                            images_class=val_images_label,\n",
    "                            transform=data_transform[\"val\"])\n",
    "    \n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=nw,\n",
    "                                               collate_fn=train_dataset.collate_fn)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                             num_workers=nw,\n",
    "                                             collate_fn=val_dataset.collate_fn)\n",
    "    \n",
    "    model = swin_large_patch4_window12_384_in22k(num_classes=num_classes).to(device)\n",
    "    \n",
    "    if weights != \"\":\n",
    "        assert os.path.exists(weights), \"weights file: '{}' not exist.\".format(weights)\n",
    "        weights_dict = torch.load(weights, map_location=device)[\"model\"]\n",
    "        print(\"載入pretrained\")\n",
    "        for k in list(weights_dict.keys()):\n",
    "            if \"head\" in k:\n",
    "                del weights_dict[k]\n",
    "        print(model.load_state_dict(weights_dict, strict=False))\n",
    "    \n",
    "    \n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=lr, weight_decay=1e-8)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        train_loss, train_acc = train_one_epoch(model=model,\n",
    "                                                optimizer=optimizer,\n",
    "                                                data_loader=train_loader,\n",
    "                                                device=device,\n",
    "                                                epoch=epoch)\n",
    "    \n",
    "        # validate\n",
    "        '''\n",
    "        val_loss, val_acc = evaluate(model=model,\n",
    "                                     data_loader=val_loader,\n",
    "                                     device=device,\n",
    "                                     epoch=epoch)\n",
    "        '''\n",
    "    \n",
    "        torch.save(model.state_dict(), \"./weights/model_{}.pth\".format(epoch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb97505",
   "metadata": {},
   "source": [
    "## Predict\n",
    "分別得到每個model的結果及softmax前的結果用於ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6410e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "\n",
      "Current is model : 55\n",
      "共24筆資料\n",
      "Finished:24\n",
      "Current is model : 60\n",
      "共24筆資料\n",
      "Finished:24\n",
      "Current is model : 65\n",
      "共24筆資料\n",
      "Finished:24\n",
      "Current is model : 75\n",
      "共24筆資料\n",
      "Finished:24"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from model import swin_large_patch4_window12_384_in22k as create_model\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]  =  \"TRUE\"\n",
    "\n",
    "\n",
    "def estimate(img,predict,df,map_,real):\n",
    "    label = df[df['img']==img]['label'].values[0]\n",
    "    if predict == label:\n",
    "        #print(\"Correct\\n\")\n",
    "        map_[str(label)] +=1\n",
    "        real += 1\n",
    "    #else:\n",
    "        #print(\"Wrong,predict:%s but correct label is : %s\"%(predict,label))\n",
    "    return map_,real\n",
    "def get_class_len(df,class_indict,num_classes):\n",
    "    class_len =[]\n",
    "    for i in range (num_classes):\n",
    "        class_len.append(len(df[df['label'] == class_indict[str(i)]]))\n",
    "    return class_len\n",
    "\n",
    "def class_accuracy(class_len,map_):\n",
    "    class_accuracy_map = map_.copy()\n",
    "    i=0\n",
    "    for item in class_accuracy_map:\n",
    "        class_accuracy_map[item] = \"%.2f\"%((map_[item]/class_len[i])*100)\n",
    "        i+=1\n",
    "    return class_accuracy_map\n",
    "\n",
    "def test():\n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"using {device} device.\")\n",
    "\n",
    "    num_classes = 219\n",
    "    img_size = 384\n",
    "    data_transform = transforms.Compose([transforms.Resize([img_size,img_size]),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "        )\n",
    "\n",
    "    test_path = \"./data/test\"\n",
    "    json_path = './class_indices.json'\n",
    "    assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n",
    "    \n",
    "    json_file = open(json_path, \"r\")\n",
    "    class_indict = json.load(json_file)\n",
    "\n",
    "    model = create_model(num_classes=num_classes).to(device)\n",
    "    \n",
    "    list_= ['55','60','65','75'] #想predict的model代號 (若命名方式不同 下面的model name 也要改)\n",
    "    columns_ = ['img']\n",
    "    for i in range(num_classes):\n",
    "        columns_.append(str(i))\n",
    "    for item in list_:\n",
    "        print(\"\\nCurrent is model : %s\"%item)\n",
    "        model_name = 'model_%s'%item\n",
    "        ensemble_name = 'swin_384_%s'%model_name\n",
    "    \n",
    "        # load model weights\n",
    "        model_weight_path = \"./weights/%s.pth\"%model_name#./weights/best_model.pth\n",
    "        model.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "        model.eval()\n",
    "        model.cuda()\n",
    "\n",
    "        \n",
    "        ensemble = pd.DataFrame(columns=columns_)\n",
    "        result = pd.DataFrame(columns=['filename','category'])\n",
    "        \n",
    "        i=0\n",
    "        f = os.listdir(test_path)\n",
    "        print(\"共%d筆資料\"%len(f))\n",
    "        for x in f:\n",
    "            img_path = test_path + \"/\" + x\n",
    "            assert os.path.exists(img_path), \"file: '{}' dose not exist.\".format(img_path)\n",
    "            img = Image.open(img_path)\n",
    "            #plt.imshow(img)\n",
    "            # [N, C, H, W]\n",
    "            img = data_transform(img)\n",
    "            # expand batch dimension\n",
    "            img = torch.unsqueeze(img, dim=0)\n",
    "        \n",
    "            # read class_indict\n",
    "            # create model\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # predict class\n",
    "                output = torch.squeeze(model(img.to(device))).cpu()\n",
    "                predict = torch.softmax(output, dim=0)\n",
    "                predict_cla = torch.argmax(predict).numpy()\n",
    "                \n",
    "            #print(\"img:%s,predict:%s\"%(x,class_indict[str(predict_cla)]))\n",
    "            \n",
    "            ensemble_output = output.numpy()\n",
    "            dict_ = {'img':x}\n",
    "\n",
    "            for y in range (num_classes):\n",
    "                dict_[str(y)] = ensemble_output[y]\n",
    "            \n",
    "            ensemble = ensemble.append(dict_,ignore_index=True)\n",
    "            #result = result.append({'filename':x,'category':class_indict[str(predict_cla)]},\n",
    "            #                   ignore_index=True)\n",
    "            #map_,real = estimate(x,class_indict[str(predict_cla)],df,map_,real)\n",
    "            i+=1\n",
    "            print(\"\\rFinished:%d\"%i,end='')\n",
    "    \n",
    "    \n",
    "        #result.to_csv(\"./result/%s_result.csv\"%ensemble_name,index=False)\n",
    "        ensemble.to_csv(\"./result/%s_ens.csv\"%ensemble_name,index=False)\n",
    "    '''\n",
    "    with open('./result/class_acc.json', 'w') as f:\n",
    "        json.dump(class_accuracy_map, f)\n",
    "    print(class_accuracy_map)\n",
    "    '''\n",
    "if __name__ == '__main__':\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbccee2",
   "metadata": {},
   "source": [
    "## Muti-Model Ensemble\n",
    "ensemble_list：要合併的結果(softmax前)\n",
    "\n",
    "ensemble_name：輸出的檔名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b493c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "已完成：1張\r",
      "已完成：2張\r",
      "已完成：3張\r",
      "已完成：4張\r",
      "已完成：5張\r",
      "已完成：6張\r",
      "已完成：7張\r",
      "已完成：8張\r",
      "已完成：9張\r",
      "已完成：10張\r",
      "已完成：11張\r",
      "已完成：12張\r",
      "已完成：13張\r",
      "已完成：14張\r",
      "已完成：15張\r",
      "已完成：16張\r",
      "已完成：17張\r",
      "已完成：18張\r",
      "已完成：19張\r",
      "已完成：20張\r",
      "已完成：21張\r",
      "已完成：22張\r",
      "已完成：23張\r",
      "已完成：24張\n",
      "Success Ensemble.\n",
      "結果輸出到./result\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]  =  \"TRUE\"\n",
    "\n",
    "\n",
    "ensemble_list = ['./result/swin_384_model_60_ens.csv',\n",
    "                 './result/swin_384_model_55_ens.csv']\n",
    "\n",
    "num_classes = 219\n",
    "ensemble_name = 'swin50_55_60_65'\n",
    "\n",
    "columns_ = ['img']\n",
    "for i in range(num_classes):\n",
    "    columns_.append(str(i))\n",
    "    \n",
    "result = pd.read_csv(ensemble_list[0],index_col=\"img\")\n",
    "result = result.sort_index(axis=0)\n",
    "\n",
    "json_path = './class_indices.json'\n",
    "json_file = open(json_path, \"r\")\n",
    "class_indict = json.load(json_file)\n",
    "\n",
    "\n",
    "for z,item in enumerate(ensemble_list):\n",
    "    if z==0:\n",
    "        continue\n",
    "    df = pd.read_csv(item,index_col=\"img\")\n",
    "    df = df.sort_index(axis=0)\n",
    "    if (list(df.index.values) == list(result.index.values)):\n",
    "        result = result.add(df)\n",
    "    else:\n",
    "        print(\"%d index error\")%z\n",
    "\n",
    "#result = result.div(len(ensemble_list))\n",
    "i=0\n",
    "data = pd.DataFrame(columns=['filename','category'])\n",
    "for item in list(result.index.values):\n",
    "    \n",
    "    raw = torch.from_numpy(result.loc[item].values)\n",
    "    output = torch.squeeze(raw).cpu()\n",
    "    predict = torch.softmax(output, dim=0)\n",
    "\n",
    "    predict_cla = torch.argmax(predict).numpy()\n",
    "    i+=1\n",
    "    print(\"\\r已完成：%d張\"%i,end='')\n",
    "\n",
    "    data = data.append({'filename':item,'category':class_indict[str(predict_cla)]},\n",
    "                      ignore_index=True)\n",
    "\n",
    "\n",
    "data.to_csv(\"./result/%s_result.csv\"%ensemble_name,index=False)\n",
    "print(\"\\nSuccess Ensemble.\")\n",
    "print(\"結果輸出到./result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b5dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
